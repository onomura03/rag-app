# PDF ドキュメント Q&A アプリ
## 概要
このプロジェクトは、PDFドキュメントの内容に基づき、AIが質問に回答するチャットアプリケーションです。Streamlitを使用して直感的なUIを構築し、LangChain、LlamaParse、ChromaDBなどの技術を組み合わせて、Retrieval-Augmented Generation (RAG) パイプラインを実装しています。

## 詳細
* **PDFファイルのアップロード**: PDFファイルをアップロードできます。

* **ベクトルデータベースの構築**: アップロードされたPDFの内容を解析し、OpenAIのEmbeddingモデルでベクトル化してChromaDBに保存します。

* **RAGパイプライン**: ユーザーの質問に対して、関連するPDFの情報を検索し、GPT-4o-miniが回答を生成します。

* **根拠情報の表示**: 回答の根拠となったPDFのファイル名とページ番号を自動で表示し、情報の信頼性を高めます。

* **パスワード認証**: アプリへのアクセスを制限し、APIキーの無駄な利用を防ぎます。

## セットアップ手順
### 前提条件
このアプリをローカル環境で動かすには、以下の3つが必要です。

* **Docker**: アプリケーションを動かすための仮想環境です。Dockerを使うことで、Pythonのバージョンやライブラリの依存関係を気にすることなく、アプリを実行できます。

* **OpenAI APIキー**: GPT-4o-miniなどのAIモデルを使用するための鍵です。OpenAIのアカウントで取得できます。

* **Llama Cloud APIキー**: PDFからテキストや構造を解析するための鍵です。Llama Cloudのアカウントで取得できます。

**1. 必要なファイルの準備**

プロジェクトを動かすためには、以下の4つのファイルが必要です。

* ```app.py```: アプリケーションのメインコードです。

* ```requirements.txt```: アプリが依存するPythonライブラリの一覧です。

* ```secrets.toml```: APIキーとパスワードを安全に管理するためのファイルです。

* ```Dockerfile```: Dockerコンテナをビルドするための設定ファイルです。

**2. ```secrets.toml```の作成**

アプリを動かすためには、APIキーとパスワードが必要です。```secrets.toml```に、ご自身のキーとパスワードを記載してください。

```
OPENAI_API_KEY="your-openai-api-key"
LLAMA_CLOUD_API_KEY="your-llama-cloud-api-key"
APP_PASSWORD="your-app-password"
```


```your-openai-api-key```、```your-llama-cloud-api-key```、そして```your-app-password```は、それぞれご自身のキーと任意のパスワードに置き換えてください。　　　　　　　　　　　　　

**3. Docker を使用した起動**
プロジェクトのフォルダに移動し、以下のコマンドを実行します。

Dockerイメージのビルド
以下のコマンドで、```Dockerfile```を使用してDockerイメージをビルドします。

```
docker build -t rag-app .
```




Dockerコンテナの起動
以下のコマンドで、コンテナを起動します。
```
docker run -p 8501:8501 rag-app
```


ブラウザで ```http://localhost:8501``` にアクセスすると、アプリが表示されます。

## アプリケーションの使い方
１. URLにアクセスし、パスワードを入力してログインします。

２. ログイン後、画面左側のサイドバーでPDFファイルをアップロードします。

３. 「データベースを更新」ボタンをクリックすると、PDFの解析とデータベースの構築が始まります。

４. 構築が完了したら、チャット入力欄に質問を入力してください。

５. AIが質問に回答し、その根拠となった情報（ファイル名とページ番号）が表示されます。
